#!/usr/bin/env python3
"""
ì™„ì „ ìˆ˜ì •ëœ ì›¹ ì•± - OCR ê²°ê³¼ íŒŒì‹± ë° í‘œì‹œ ë¬¸ì œ í•´ê²°
web/app.py íŒŒì¼ì„ ì´ ë‚´ìš©ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”.
"""

import os
import json
import uuid
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

from flask import Flask, render_template, request, jsonify, send_file, redirect, url_for, flash
from werkzeug.utils import secure_filename
from werkzeug.exceptions import RequestEntityTooLarge
import threading
import time

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import (ê²½ë¡œ ì¡°ì • í•„ìš”)
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.pdf_handler import PDFHandler
from core.image_processor import ImageProcessor
from core.ocr_engine import OCREngine
from core.text_postprocessor import TextPostProcessor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Flask ì•± ì„¤ì •
app = Flask(__name__)
app.config.update(
    SECRET_KEY=os.environ.get('SECRET_KEY', 'dev-secret-key-change-in-production'),
    UPLOAD_FOLDER=os.environ.get('UPLOAD_FOLDER', 'uploads'),
    MAX_CONTENT_LENGTH=16 * 1024 * 1024,  # 16MB
    RESULT_FOLDER=os.environ.get('RESULT_FOLDER', 'static/results'),
    PERMANENT_SESSION_LIFETIME=1800  # 30ë¶„
)

# ë””ë ‰í† ë¦¬ ìƒì„±
for folder in [app.config['UPLOAD_FOLDER'], app.config['RESULT_FOLDER']]:
    Path(folder).mkdir(parents=True, exist_ok=True)

# ì „ì—­ ë³€ìˆ˜ë¡œ ì²˜ë¦¬ ìƒíƒœ ê´€ë¦¬
processing_jobs: Dict[str, Dict[str, Any]] = {}


class OCRProcessor:
    """OCR ì²˜ë¦¬ í†µí•© í´ë˜ìŠ¤"""

    def __init__(self):
        self.pdf_handler = None
        self.image_processor = None
        self.ocr_engine = None
        self.text_processor = None
        self._initialize_components()

    def _initialize_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            self.pdf_handler = PDFHandler()
            self.image_processor = ImageProcessor()
            self.ocr_engine = OCREngine()
            self.text_processor = TextPostProcessor()
            logger.info("OCR processor components initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize OCR components: {str(e)}")
            raise

    def process_pdf(self, pdf_path: str, job_id: str, options: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ PDF ì²˜ë¦¬ í•¨ìˆ˜"""
        try:
            # 1. PDF ìœ íš¨ì„± ê²€ì‚¬
            self._update_job_status(job_id, 'validating', 5, 'PDF íŒŒì¼ ê²€ì¦ ì¤‘...')
            validation = self.pdf_handler.validate_pdf(pdf_path)
            if not validation['is_valid']:
                raise ValueError(f"Invalid PDF: {validation['error_message']}")

            # 2. PDF ì •ë³´ ì¶”ì¶œ
            self._update_job_status(job_id, 'extracting_info', 10, 'PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘...')
            pdf_info = self.pdf_handler.extract_pdf_info(pdf_path)

            # 3. PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            self._update_job_status(job_id, 'converting', 20, 'PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì¤‘...')

            output_dir = Path(app.config['RESULT_FOLDER']) / job_id
            output_dir.mkdir(exist_ok=True)
            self.pdf_handler.output_dir = output_dir

            def conversion_progress(current, total, filename):
                progress = 20 + (current / total) * 30  # 20% ~ 50%
                self._update_job_status(job_id, 'converting', progress, f'í˜ì´ì§€ {current}/{total} ë³€í™˜ ì¤‘...')

            image_paths = self.pdf_handler.convert_to_images(
                pdf_path,
                dpi=options.get('dpi', 300),
                progress_callback=conversion_progress
            )

            # 4. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì˜µì…˜)
            if options.get('preprocess', True):
                self._update_job_status(job_id, 'preprocessing', 50, 'ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...')

                preprocessed_dir = output_dir / 'preprocessed'
                preprocessed_dir.mkdir(exist_ok=True)

                def preprocess_progress(current, total, filename):
                    progress = 50 + (current / total) * 20  # 50% ~ 70%
                    self._update_job_status(job_id, 'preprocessing', progress, f'ì´ë¯¸ì§€ {current}/{total} ì „ì²˜ë¦¬ ì¤‘...')

                config = options.get('preprocess_config', {})
                preprocessed_paths = self.image_processor.batch_preprocess(
                    image_paths,
                    str(preprocessed_dir),
                    config=config,
                    progress_callback=preprocess_progress
                )

                final_image_paths = [path for path in preprocessed_paths if path is not None]
            else:
                final_image_paths = image_paths

            # 5. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ - ğŸ”¥ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„
            self._update_job_status(job_id, 'ocr', 70, 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...')

            def ocr_progress(current, total, filename):
                progress = 70 + (current / total) * 20  # 70% ~ 90%
                self._update_job_status(job_id, 'ocr', progress, f'OCR {current}/{total} ì²˜ë¦¬ ì¤‘...')

            # ê°œì„ ëœ OCR ì—”ì§„ ì‚¬ìš©
            logger.info(f"ğŸš€ ê°œì„ ëœ OCR ì²˜ë¦¬ ì‹œì‘: {len(final_image_paths)}ê°œ ì´ë¯¸ì§€")
            ocr_results = self.ocr_engine.batch_extract(final_image_paths, ocr_progress)

            # 6. í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ - ğŸ”¥ ê²°ê³¼ ì²˜ë¦¬ ì™„ì „ ìˆ˜ì •
            self._update_job_status(job_id, 'postprocessing', 90, 'í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ì¤‘...')

            pages_data = []
            total_successful_pages = 0
            total_text_regions = 0
            total_characters = 0

            for i, image_path in enumerate(final_image_paths):
                page_number = i + 1
                ocr_result = ocr_results.get(image_path, [])

                logger.info(f"ğŸ“„ í˜ì´ì§€ {page_number} OCR ê²°ê³¼ ì²˜ë¦¬: {len(ocr_result)}ê°œ ì˜ì—­")

                # ğŸ”¥ í•µì‹¬ ìˆ˜ì •: OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text_regions = []
                page_has_text = False

                # OCR ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ì´ê³  ê° í•­ëª©ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                for idx, region in enumerate(ocr_result):
                    if isinstance(region, dict) and 'text' in region:
                        text = region['text'].strip()
                        if text and len(text) > 0:
                            text_regions.append(text)
                            page_has_text = True
                            logger.info(f"    âœ… ì˜ì—­ {idx + 1}: '{text[:50]}{'...' if len(text) > 50 else ''}'")

                # í…ìŠ¤íŠ¸ ê²°í•©
                combined_text = '\n'.join(text_regions) if text_regions else ''

                # í†µê³„ ì—…ë°ì´íŠ¸
                if page_has_text:
                    total_successful_pages += 1
                    total_text_regions += len(text_regions)
                    total_characters += len(combined_text)

                logger.info(f"âœ… í˜ì´ì§€ {page_number} ìµœì¢… ê²°ê³¼: {len(text_regions)}ê°œ ì˜ì—­, {len(combined_text)}ê¸€ì")

                # ğŸ”¥ í•µì‹¬: extraction_success í•„ë“œ ì¶”ê°€ (í…œí”Œë¦¿ì—ì„œ í•„ìš”)
                page_data = {
                    'page_number': page_number,
                    'image_path': image_path,
                    'text_regions': text_regions,
                    'combined_text': combined_text,
                    'text_count': len(text_regions),
                    'has_text': page_has_text,
                    'extraction_success': page_has_text,  # ğŸ”¥ ì¤‘ìš”: í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©
                    'character_count': len(combined_text),
                    'ocr_data': str(type(ocr_result)),  # ë””ë²„ê·¸ìš©
                    'debug_info': [
                        f"OCR ê²°ê³¼ íƒ€ì…: {type(ocr_result)}",
                        f"OCR ê²°ê³¼ ê¸¸ì´: {len(ocr_result)}",
                        f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì˜ì—­: {len(text_regions)}",
                        f"ì´ ê¸€ì ìˆ˜: {len(combined_text)}"
                    ]
                }

                # í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ì ìš© (í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
                if options.get('postprocess', True) and combined_text.strip():
                    try:
                        processed_text = self.text_processor.process_page_text(combined_text, page_number)
                        page_data['processed_text'] = processed_text
                        logger.debug(f"    í›„ì²˜ë¦¬ ì™„ë£Œ: í˜ì´ì§€ {page_number}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ í˜ì´ì§€ {page_number} í›„ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

                pages_data.append(page_data)

            # 7. ê²°ê³¼ í†µí•© ë° ìš”ì•½
            logger.info(f"ğŸ¯ ì „ì²´ ì²˜ë¦¬ ê²°ê³¼:")
            logger.info(f"  - ì´ í˜ì´ì§€: {len(pages_data)}")
            logger.info(f"  - í…ìŠ¤íŠ¸ê°€ ìˆëŠ” í˜ì´ì§€: {total_successful_pages}")
            logger.info(f"  - ì´ í…ìŠ¤íŠ¸ ì˜ì—­: {total_text_regions}")
            logger.info(f"  - ì´ ê¸€ì ìˆ˜: {total_characters}")

            success_rate = (total_successful_pages / len(pages_data) * 100) if pages_data else 0
            logger.info(f"  - ì„±ê³µë¥ : {success_rate:.1f}%")

            results = {
                'pdf_info': pdf_info,
                'processing_options': options,
                'pages': pages_data,
                'job_id': job_id,
                'processed_at': datetime.now().isoformat(),
                'processing_summary': {
                    'total_pages': len(pages_data),
                    'successful_pages': total_successful_pages,
                    'success_rate': success_rate,
                    'total_text_regions': total_text_regions,
                    'total_characters': total_characters
                }
            }

            # ë¬¸ì„œ ìš”ì•½ ìƒì„± (í›„ì²˜ë¦¬ í™œì„±í™” ì‹œ)
            if options.get('postprocess', True) and total_successful_pages > 0:
                try:
                    processed_pages = [page['processed_text'] for page in pages_data if 'processed_text' in page]
                    if processed_pages:
                        document_summary = self.text_processor.generate_document_summary(processed_pages)
                        results['document_summary'] = document_summary
                        logger.info("ğŸ“Š ë¬¸ì„œ ìš”ì•½ ìƒì„± ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ ë¬¸ì„œ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}")

            # 8. ê²°ê³¼ ì €ì¥
            self._save_results(results, output_dir)

            # ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
            if total_successful_pages > 0:
                self._update_job_status(job_id, 'completed', 100,
                                        f'ì²˜ë¦¬ ì™„ë£Œ! ({total_successful_pages}/{len(pages_data)} í˜ì´ì§€ ì„±ê³µ)')
            else:
                self._update_job_status(job_id, 'completed', 100, 'ì²˜ë¦¬ ì™„ë£Œ (í…ìŠ¤íŠ¸ ì—†ìŒ)')

            processing_jobs[job_id]['results'] = results
            return results

        except Exception as e:
            error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            self._update_job_status(job_id, 'error', 0, error_msg)
            logger.error(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨ (Job: {job_id}): {str(e)}")
            raise

    def _update_job_status(self, job_id: str, status: str, progress: float, message: str):
        """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if job_id in processing_jobs:
            processing_jobs[job_id].update({
                'status': status,
                'progress': progress,
                'message': message,
                'updated_at': datetime.now().isoformat()
            })

    def _save_results(self, results: Dict[str, Any], output_dir: Path):
        """ê²°ê³¼ íŒŒì¼ ì €ì¥ - ì™„ì „ ìˆ˜ì • ë²„ì „"""
        try:
            # 1. JSON ê²°ê³¼ ì €ì¥
            json_path = output_dir / 'results.json'
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"JSON ê²°ê³¼ ì €ì¥: {json_path}")

            # 2. í…ìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
            txt_path = output_dir / 'extracted_text.txt'
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(f"OCR ì²˜ë¦¬ ê²°ê³¼\n")
                f.write(f"ì²˜ë¦¬ ì‹œê°„: {results.get('processed_at', 'Unknown')}\n")
                f.write(f"ì„±ê³µë¥ : {results.get('processing_summary', {}).get('success_rate', 0):.1f}%\n")
                f.write("=" * 50 + "\n\n")

                for page in results.get('pages', []):
                    page_number = page.get('page_number', 'Unknown')
                    f.write(f"í˜ì´ì§€ {page_number}\n")
                    f.write("-" * 20 + "\n")

                    # ì•ˆì „í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    combined_text = page.get('combined_text', '')
                    has_text = page.get('has_text', False)
                    text_count = page.get('text_count', 0)

                    if has_text or combined_text.strip():
                        f.write(f"í…ìŠ¤íŠ¸ ì˜ì—­ ìˆ˜: {text_count}\n")
                        f.write(f"ê¸€ì ìˆ˜: {page.get('character_count', len(combined_text))}\n\n")
                        f.write(combined_text if combined_text.strip() else "í…ìŠ¤íŠ¸ ì—†ìŒ")
                    else:
                        f.write("ì´ í˜ì´ì§€ì—ì„œëŠ” í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                    f.write("\n\n")

            logger.info(f"í…ìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {txt_path}")

            # 3. CSV ìš”ì•½ ì €ì¥ (ì²˜ë¦¬ ìš”ì•½ì´ ìˆëŠ” ê²½ìš°)
            if 'processing_summary' in results:
                csv_path = output_dir / 'summary.csv'
                try:
                    import csv
                    with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                        writer = csv.writer(f)

                        # í—¤ë”
                        writer.writerow([
                            'í˜ì´ì§€', 'í…ìŠ¤íŠ¸_ì˜ì—­_ìˆ˜', 'ê¸€ì_ìˆ˜', 'í…ìŠ¤íŠ¸_ìˆìŒ', 'í…ìŠ¤íŠ¸_ë¯¸ë¦¬ë³´ê¸°'
                        ])

                        # ë°ì´í„°
                        for page in results.get('pages', []):
                            preview = page.get('combined_text', '')[:100].replace('\n', ' ')
                            if len(preview) > 97:
                                preview += '...'

                            writer.writerow([
                                page.get('page_number', 0),
                                page.get('text_count', 0),
                                page.get('character_count', 0),
                                'Y' if page.get('has_text', False) else 'N',
                                preview
                            ])

                    logger.info(f"CSV ìš”ì•½ ì €ì¥: {csv_path}")

                except Exception as e:
                    logger.warning(f"CSV ì €ì¥ ì‹¤íŒ¨: {str(e)}")

            logger.info(f"âœ… ëª¨ë“  ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}")

        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            raise


# OCR í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤
ocr_processor = OCRProcessor()


def process_pdf_async(job_id: str, pdf_path: str, options: Dict[str, Any]):
    """ë¹„ë™ê¸° PDF ì²˜ë¦¬"""
    try:
        ocr_processor.process_pdf(pdf_path, job_id, options)
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            if os.path.exists(pdf_path):
                os.remove(pdf_path)
        except:
            pass


@app.errorhandler(RequestEntityTooLarge)
def handle_file_too_large(e):
    return jsonify({'error': 'íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. 16MB ì´í•˜ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.'}), 413


@app.errorhandler(404)
def handle_not_found(e):
    return render_template('error.html',
                           error_code=404,
                           error_message='í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'), 404


@app.errorhandler(500)
def handle_internal_error(e):
    return render_template('error.html',
                           error_code=500,
                           error_message='ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'), 500


def allowed_file(filename: str) -> bool:
    """í—ˆìš©ëœ íŒŒì¼ í™•ì¥ì í™•ì¸"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in {'pdf'}


@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html')


@app.route('/upload', methods=['POST'])
def upload_file():
    """íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ì‹œì‘"""
    try:
        # íŒŒì¼ í™•ì¸
        if 'file' not in request.files:
            return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400

        if not file or not allowed_file(file.filename):
            return jsonify({'error': 'PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.'}), 400

        # íŒŒì¼ ì €ì¥
        filename = secure_filename(file.filename)
        job_id = str(uuid.uuid4())
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], f"{job_id}_{filename}")
        file.save(file_path)

        # ì²˜ë¦¬ ì˜µì…˜ ê°€ì ¸ì˜¤ê¸°
        options = {
            'dpi': int(request.form.get('dpi', 300)),
            'preprocess': request.form.get('preprocess') == 'true',
            'postprocess': request.form.get('postprocess') == 'true',
            'preprocess_config': {}
        }

        # ì‘ì—… ìƒíƒœ ì´ˆê¸°í™”
        processing_jobs[job_id] = {
            'job_id': job_id,
            'filename': filename,
            'status': 'queued',
            'progress': 0,
            'message': 'ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...',
            'created_at': datetime.now().isoformat(),
            'options': options
        }

        # ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘
        thread = threading.Thread(
            target=process_pdf_async,
            args=(job_id, file_path, options)
        )
        thread.daemon = True
        thread.start()

        return jsonify({
            'job_id': job_id,
            'message': 'íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ. ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.',
            'filename': filename
        })

    except Exception as e:
        logger.error(f"Upload error: {str(e)}")
        return jsonify({'error': f'ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500


@app.route('/status/<job_id>')
def get_status(job_id: str):
    """ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ"""
    if job_id not in processing_jobs:
        return jsonify({'error': 'ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

    job_data = processing_jobs[job_id].copy()
    # ê²°ê³¼ ë°ì´í„°ëŠ” ì œì™¸ (í¬ê¸° ë•Œë¬¸)
    job_data.pop('results', None)

    return jsonify(job_data)


@app.route('/results/<job_id>')
def get_results(job_id: str):
    """ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ ì²˜ë¦¬ ê²°ê³¼ í˜ì´ì§€"""
    if job_id not in processing_jobs:
        flash('ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'error')
        return redirect(url_for('index'))

    job = processing_jobs[job_id]
    if job['status'] != 'completed':
        flash('ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.', 'warning')
        return redirect(url_for('index'))

    if 'results' not in job:
        flash('ê²°ê³¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'error')
        return redirect(url_for('index'))

    # ğŸ”¥ í…œí”Œë¦¿ ë Œë”ë§ ì‹œ í•„ìš”í•œ ëª¨ë“  ë°ì´í„° ì „ë‹¬
    return render_template('results.html',
                           job_id=job_id,
                           results=job['results'],
                           job_info=job)


@app.route('/download/<job_id>/<format>')
def download_results(job_id: str, format: str):
    """ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    if job_id not in processing_jobs:
        return jsonify({'error': 'ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

    job = processing_jobs[job_id]
    if job['status'] != 'completed':
        return jsonify({'error': 'ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400

    results_dir = Path(app.config['RESULT_FOLDER']) / job_id

    try:
        if format == 'json':
            file_path = results_dir / 'results.json'
            if file_path.exists():
                return send_file(file_path, as_attachment=True,
                                 download_name=f"{job['filename']}_results.json")

        elif format == 'txt':
            file_path = results_dir / 'extracted_text.txt'
            if file_path.exists():
                return send_file(file_path, as_attachment=True,
                                 download_name=f"{job['filename']}_text.txt")

        elif format == 'debug':
            file_path = results_dir / 'debug_info.json'
            if file_path.exists():
                return send_file(file_path, as_attachment=True,
                                 download_name=f"{job['filename']}_debug.json")

        elif format == 'csv':
            file_path = results_dir / 'summary.csv'
            if file_path.exists():
                return send_file(file_path, as_attachment=True,
                                 download_name=f"{job['filename']}_summary.csv")

        return jsonify({'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

    except Exception as e:
        logger.error(f"Download error: {str(e)}")
        return jsonify({'error': f'ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500


@app.route('/health')
def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ í™•ì¸
        status = {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'components': {
                'pdf_handler': ocr_processor.pdf_handler is not None,
                'image_processor': ocr_processor.image_processor is not None,
                'ocr_engine': ocr_processor.ocr_engine is not None,
                'text_processor': ocr_processor.text_processor is not None
            },
            'active_jobs': len([job for job in processing_jobs.values() if job['status'] == 'processing']),
            'total_jobs': len(processing_jobs)
        }

        # ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒì¸ì§€ í™•ì¸
        if not all(status['components'].values()):
            status['status'] = 'degraded'
            return jsonify(status), 503

        return jsonify(status)

    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 503


# ğŸ”¥ Jinja2 í•„í„° ì¶”ê°€ (í…œí”Œë¦¿ì—ì„œ ìˆ«ì í¬ë§·íŒ…ì— í•„ìš”)
@app.template_filter('number_format')
def number_format_filter(value):
    """ìˆ«ì í¬ë§· í•„í„°"""
    try:
        return f"{int(value):,}"
    except (ValueError, TypeError):
        return value


@app.template_filter('file_size')
def file_size_filter(size_bytes):
    """íŒŒì¼ í¬ê¸° í¬ë§· í•„í„°"""
    try:
        size = int(size_bytes)
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f} {unit}"
            size /= 1024
        return f"{size:.1f} TB"
    except (ValueError, TypeError):
        return "Unknown"


def main():
    """ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ í•¨ìˆ˜"""
    # ê°œë°œ ì„œë²„ ì‹¤í–‰
    debug_mode = os.environ.get('FLASK_ENV', 'production') == 'development'
    port = int(os.environ.get('PORT', 5000))
    host = os.environ.get('HOST', '0.0.0.0')

    logger.info(f"Starting Flask app on {host}:{port} (debug={debug_mode})")

    app.run(
        host=host,
        port=port,
        debug=debug_mode,
        threaded=True
    )


if __name__ == '__main__':
    main()